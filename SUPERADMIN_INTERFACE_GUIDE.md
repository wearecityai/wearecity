# ğŸ›ï¸ GuÃ­a de Interfaz SuperAdmin - Agentes Inteligentes

## ğŸ“‹ Resumen

La secciÃ³n **Agentes Inteligentes** del SuperAdmin te permite gestionar completamente el sistema dinÃ¡mico de scraping y RAG sin tocar cÃ³digo. Todo se maneja desde la interfaz web con configuraciÃ³n en tiempo real.

---

## ğŸ—ï¸ Arquitectura Implementada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SUPERADMIN INTERFACE                      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Config    â”‚  â”‚  Scraping   â”‚  â”‚ Monitoring  â”‚        â”‚
â”‚  â”‚  Manager    â”‚  â”‚  Control    â”‚  â”‚ Dashboard   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DYNAMIC SYSTEM                           â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Firestore  â”‚  â”‚ Agent Engineâ”‚  â”‚  Puppeteer  â”‚        â”‚
â”‚  â”‚ Config DB   â”‚  â”‚  (Vertex)   â”‚  â”‚  Service    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Funcionalidades Principales

### **âœ… 1. GestiÃ³n DinÃ¡mica de URLs**
- **Configurar URLs por categorÃ­a**: Eventos, TrÃ¡mites, Turismo, etc.
- **ValidaciÃ³n automÃ¡tica**: VerificaciÃ³n de URLs en tiempo real
- **Vista previa**: Abrir sitios web directamente desde la interfaz
- **Sin hardcoding**: Todas las URLs se almacenan en Firestore

### **âœ… 2. Scraping Inteligente**
- **Scraping manual**: Ejecutar bajo demanda para cualquier ciudad
- **URLs dinÃ¡micas**: El agente consulta automÃ¡ticamente las URLs configuradas
- **Scraping programado**: Diario, semanal y mensual automÃ¡tico
- **Monitoreo**: Ver estado y resultados en tiempo real

### **âœ… 3. ConfiguraciÃ³n Centralizada**
- **Por ciudad**: ConfiguraciÃ³n independiente para cada ciudad
- **Selectores CSS**: Personalizar cÃ³mo extraer datos de cada sitio
- **HabilitaciÃ³n/DeshabilitaciÃ³n**: Control granular del scraping
- **InformaciÃ³n bÃ¡sica**: Nombre, poblaciÃ³n, provincia, etc.

### **âœ… 4. Monitoreo y EstadÃ­sticas**
- **Estado de servicios**: Ver si todos los componentes funcionan
- **MÃ©tricas en tiempo real**: Eventos, fuentes RAG, ciudades activas
- **Alertas**: Notificaciones automÃ¡ticas de problemas
- **HistÃ³rico**: MÃ©tricas de las Ãºltimas 24h, 7d, 30d

---

## ğŸ–¥ï¸ Interfaz de Usuario

### **ğŸ“Š Tab: Resumen**
- **EstadÃ­sticas principales**: Eventos, fuentes RAG, ciudades
- **Acciones rÃ¡pidas**: Scraping, actualizar stats, limpiar datos
- **Estado del sistema**: Agent Engine, Puppeteer, Firestore

### **âš™ï¸ Tab: ConfiguraciÃ³n**
- **InformaciÃ³n bÃ¡sica**: Nombre, sitio web oficial
- **URLs por categorÃ­a**:
  - ğŸ“… **Eventos**: URLs de agendas municipales
  - ğŸ“‹ **TrÃ¡mites**: URLs de servicios municipales
  - ğŸ“° **Noticias**: URLs de noticias locales
  - ğŸŒ **Turismo**: URLs de informaciÃ³n turÃ­stica
  - ğŸ“ **Contacto**: URLs de contacto municipal
  - ğŸ”§ **Servicios**: URLs de servicios pÃºblicos
- **ConfiguraciÃ³n de scraping**: Selectores CSS personalizados

### **ğŸ¤– Tab: Scraping**
- **Scraping manual**: Ejecutar inmediatamente
- **URLs configuradas**: Ver quÃ© URLs se van a scrapear
- **Scraping programado**: Estado de jobs automÃ¡ticos
- **Vista previa**: Abrir sitios web para verificar

### **ğŸ“ˆ Tab: Monitoreo**
- **Estado de servicios**: Salud de todos los componentes
- **MÃ©tricas**: NÃºmeros actuales del sistema
- **Acciones de mantenimiento**: Limpiar datos, estadÃ­sticas

---

## ğŸš€ CÃ³mo Usar la Interfaz

### **ğŸ Paso 1: Acceder a la SecciÃ³n**
1. Iniciar sesiÃ³n como SuperAdmin
2. Ir al Dashboard SuperAdmin
3. Hacer clic en "Agentes Inteligentes" en el sidebar

### **ğŸ™ï¸ Paso 2: Seleccionar Ciudad**
1. Usar el selector de ciudad en la esquina superior derecha
2. Elegir entre Valencia, La Vila Joiosa, Alicante
3. La configuraciÃ³n se carga automÃ¡ticamente

### **âš™ï¸ Paso 3: Configurar URLs**
1. Ir al tab "ConfiguraciÃ³n"
2. Completar informaciÃ³n bÃ¡sica de la ciudad
3. Agregar URLs por categorÃ­a:
   ```
   ğŸ“… Eventos: https://www.ciudad.es/agenda
   ğŸ“‹ TrÃ¡mites: https://www.ciudad.es/tramites
   ğŸŒ Turismo: https://www.ciudad.es/turismo
   ```
4. Configurar selectores CSS si es necesario
5. Hacer clic en "Guardar ConfiguraciÃ³n"

### **ğŸ•·ï¸ Paso 4: Ejecutar Scraping**
1. Ir al tab "Scraping"
2. Hacer clic en "Ejecutar Scraping Completo"
3. El agente:
   - Consulta las URLs configuradas
   - Scrapea cada URL automÃ¡ticamente
   - Inserta los eventos en el sistema RAG
4. Ver resultados en tiempo real

### **ğŸ“Š Paso 5: Monitorear Resultados**
1. Ir al tab "Resumen" o "Monitoreo"
2. Ver estadÃ­sticas actualizadas
3. Verificar que no hay alertas
4. Comprobar que los servicios estÃ¡n operativos

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### **ğŸ¯ Selectores CSS Personalizados**
```css
/* Ejemplos de selectores comunes */
Contenedor de eventos: article, .post, .event-item
TÃ­tulo: h1, h2, h3, .entry-title, .event-title
DescripciÃ³n: .entry-content, .event-description, .content
Fecha: .event-date, .entry-date, time
UbicaciÃ³n: .event-location, .venue, .location
```

### **ğŸ”— Tipos de URLs Soportadas**
- âœ… **HTTPS**: Requerido para seguridad
- âœ… **Sitios municipales**: Ayuntamientos oficiales
- âœ… **Agendas culturales**: Eventos y actividades
- âœ… **Portales de trÃ¡mites**: Servicios municipales
- âœ… **Sitios turÃ­sticos**: InformaciÃ³n para visitantes

### **â° Scraping Programado**
- **Diario (6:00 AM)**: Agenda principal de cada ciudad
- **Semanal (Lunes 3:00 AM)**: Fuentes adicionales
- **Mensual (DÃ­a 1, 2:00 AM)**: Limpieza y actualizaciÃ³n completa

---

## ğŸš¨ ResoluciÃ³n de Problemas

### **âŒ Error: "No hay URLs configuradas"**
**SoluciÃ³n**: Ir a ConfiguraciÃ³n â†’ Agregar URLs de eventos

### **âŒ Error: "URL invÃ¡lida"**
**SoluciÃ³n**: Verificar que la URL empieza con https://

### **âŒ Error: "Scraping fallÃ³"**
**Soluciones**:
1. Verificar que el sitio web estÃ© accesible
2. Comprobar selectores CSS
3. Ver si el sitio requiere JavaScript

### **âŒ Error: "Sin eventos extraÃ­dos"**
**Soluciones**:
1. Ajustar selectores CSS
2. Verificar que la pÃ¡gina tenga eventos
3. Comprobar estructura HTML del sitio

---

## ğŸ¯ Mejores PrÃ¡cticas

### **âœ… ConfiguraciÃ³n de URLs**
- Usar URLs oficiales del ayuntamiento
- Verificar que las pÃ¡ginas tengan eventos regulares
- Probar URLs antes de guardar
- Mantener URLs actualizadas

### **âœ… Selectores CSS**
- Usar selectores especÃ­ficos pero flexibles
- Probar con mÃºltiples pÃ¡ginas del sitio
- Actualizar si el sitio cambia estructura
- Documentar cambios importantes

### **âœ… Monitoreo Regular**
- Revisar estadÃ­sticas semanalmente
- Verificar alertas del sistema
- Comprobar que el scraping programado funciona
- Limpiar datos obsoletos mensualmente

---

## ğŸ“ˆ MÃ©tricas Importantes

### **ğŸ¯ Indicadores de Ã‰xito**
- **Eventos extraÃ­dos**: > 10 eventos por ciudad por semana
- **Tasa de Ã©xito**: > 90% de URLs scrapeadas exitosamente
- **Tiempo de respuesta**: < 30 segundos por scraping
- **Disponibilidad**: > 99% de uptime de servicios

### **âš ï¸ SeÃ±ales de Alerta**
- Cero eventos extraÃ­dos por varios dÃ­as
- Errores frecuentes en scraping
- URLs que devuelven errores 404/500
- Servicios marcados como "degraded" o "down"

---

## ğŸ”’ Seguridad y Permisos

### **ğŸ‘‘ Solo SuperAdmin**
- **ConfiguraciÃ³n**: Solo SuperAdmins pueden cambiar URLs
- **Scraping manual**: Solo SuperAdmins pueden ejecutar
- **Limpieza de datos**: OperaciÃ³n destructiva protegida
- **Monitoreo**: Acceso completo a mÃ©tricas sensibles

### **ğŸ‘¤ Usuarios PÃºblicos**
- **Consultas**: Solo pueden hacer preguntas al agente
- **Sin modificaciÃ³n**: No pueden cambiar configuraciÃ³n
- **Sin scraping**: No pueden ejecutar operaciones de scraping
- **RAG de solo lectura**: Solo consultan informaciÃ³n existente

---

## ğŸŠ Â¡Sistema Completamente Operativo!

### **âœ… Lo que has conseguido:**
1. **ğŸ›ï¸ Interfaz completa**: GestiÃ³n total desde el frontend
2. **ğŸ”„ Sistema dinÃ¡mico**: URLs configurables sin tocar cÃ³digo
3. **ğŸ¤– Agente inteligente**: Scraping automÃ¡tico e inteligente
4. **ğŸ“Š Monitoreo completo**: Visibilidad total del sistema
5. **ğŸ”’ Seguridad robusta**: SeparaciÃ³n admin/pÃºblico
6. **âš¡ Tiempo real**: Cambios inmediatos sin redespliegue

### **ğŸš€ PrÃ³ximos pasos:**
- Los SuperAdmins ya pueden gestionar todo desde la interfaz
- El sistema se actualiza automÃ¡ticamente con scraping programado
- Los usuarios finales obtienen informaciÃ³n actualizada
- El agente consulta siempre las URLs mÃ¡s recientes

**Â¡El sistema de agentes inteligentes estÃ¡ listo para producciÃ³n!** ğŸ‰
