#!/usr/bin/env python3
"""
Probar generaciÃ³n de embeddings y bÃºsqueda vectorial
"""

import sys
import json

# Agregar el path del agente
sys.path.insert(0, '/Users/tonillorens/Desktop/wearecity_app/.venv/lib/python3.12/site-packages')

try:
    import firebase_admin
    from firebase_admin import credentials, firestore
    import vertexai
    from vertexai.language_models import TextEmbeddingModel
    
    print("âœ… Dependencias importadas correctamente")
except ImportError as e:
    print(f"âŒ Error importando dependencias: {e}")
    sys.exit(1)

def test_embedding_generation():
    """Probar generaciÃ³n de embeddings"""
    print("ğŸ§  Probando generaciÃ³n de embeddings...")
    
    try:
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        
        # Usar el modelo de embeddings
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Textos de prueba
        test_texts = [
            "Festival de mÃºsica en Valencia con conciertos gratuitos",
            "TrÃ¡mites de empadronamiento en el ayuntamiento",
            "Fiestas tradicionales de Moros y Cristianos",
            "InformaciÃ³n turÃ­stica sobre playas y museos"
        ]
        
        embeddings_results = []
        
        for text in test_texts:
            print(f"   ğŸ” Generando embedding para: {text[:50]}...")
            
            try:
                embeddings = model.get_embeddings([text])
                
                if embeddings and len(embeddings) > 0:
                    vector = embeddings[0].values
                    embeddings_results.append({
                        "text": text,
                        "embedding": vector,
                        "dimensions": len(vector),
                        "success": True
                    })
                    print(f"   âœ… Embedding generado: {len(vector)} dimensiones")
                else:
                    print(f"   âŒ No se pudo generar embedding")
                    embeddings_results.append({
                        "text": text,
                        "embedding": [],
                        "dimensions": 0,
                        "success": False
                    })
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
                embeddings_results.append({
                    "text": text,
                    "embedding": [],
                    "dimensions": 0,
                    "success": False,
                    "error": str(e)
                })
        
        # Resumen
        successful = sum(1 for r in embeddings_results if r['success'])
        print(f"\nğŸ“Š Resumen embeddings:")
        print(f"   âœ… Exitosos: {successful}/{len(test_texts)}")
        
        if successful > 0:
            avg_dimensions = sum(r['dimensions'] for r in embeddings_results if r['success']) / successful
            print(f"   ğŸ“ Dimensiones promedio: {avg_dimensions:.0f}")
        
        return embeddings_results
        
    except Exception as e:
        print(f"âŒ Error en generaciÃ³n de embeddings: {e}")
        return []

def test_vector_similarity():
    """Probar cÃ¡lculo de similitud vectorial"""
    print("\nğŸ”¢ Probando cÃ¡lculo de similitud vectorial...")
    
    try:
        import numpy as np
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Textos relacionados para probar similitud
        queries = [
            "festivales de mÃºsica",
            "conciertos y eventos culturales",
            "trÃ¡mites municipales",
            "empadronamiento y documentaciÃ³n"
        ]
        
        documents = [
            "Festival de mÃºsica en Valencia con conciertos gratuitos",
            "Concierto de jazz en el teatro municipal",
            "TrÃ¡mites de empadronamiento en el ayuntamiento",
            "Documentos necesarios para registrarse como residente"
        ]
        
        print("   ğŸ” Generando embeddings para consultas y documentos...")
        
        # Generar embeddings
        query_embeddings = model.get_embeddings(queries)
        doc_embeddings = model.get_embeddings(documents)
        
        def cosine_similarity(vec1, vec2):
            """Calcular similitud coseno"""
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0
            
            return np.dot(vec1, vec2) / (norm1 * norm2)
        
        print("\n   ğŸ“Š Matriz de similitudes:")
        print("   " + "-" * 60)
        
        # Calcular similitudes
        for i, query in enumerate(queries):
            print(f"   ğŸ” '{query[:30]}...'")
            
            similarities = []
            for j, doc in enumerate(documents):
                similarity = cosine_similarity(
                    query_embeddings[i].values,
                    doc_embeddings[j].values
                )
                similarities.append((doc[:40], similarity))
            
            # Ordenar por similitud
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # Mostrar los mÃ¡s similares
            for doc_text, sim_score in similarities[:2]:
                print(f"      âœ… {sim_score:.3f} - {doc_text}...")
        
        print("   âœ… Similitud vectorial funcionando correctamente")
        return True
        
    except Exception as e:
        print(f"âŒ Error en similitud vectorial: {e}")
        return False

def test_rag_with_embeddings():
    """Probar inserciÃ³n y bÃºsqueda con embeddings"""
    print("\nğŸ—‚ï¸ Probando RAG con embeddings...")
    
    try:
        # Inicializar Firebase Admin
        if not firebase_admin._apps:
            firebase_admin.initialize_app()
        
        db = firestore.client()
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Datos de prueba con embeddings
        test_event = {
            "title": "Concierto de Jazz Vectorial",
            "description": "Concierto de jazz experimental con artistas locales en el auditorio municipal",
            "date": "2025-09-30",
            "time": "21:00",
            "location": "Auditorio Municipal, Valencia",
            "category": "musica",
            "tags": ["jazz", "experimental", "local", "auditorio"],
            "source": "test_vector_embeddings",
            "confidence": 0.95
        }
        
        # Generar embedding para el evento
        content_for_embedding = f"""
        TÃ­tulo: {test_event['title']}
        DescripciÃ³n: {test_event['description']}
        UbicaciÃ³n: {test_event['location']}
        CategorÃ­a: {test_event['category']}
        Etiquetas: {', '.join(test_event['tags'])}
        Ciudad: Valencia
        """.strip()
        
        print("   ğŸ§  Generando embedding para evento de prueba...")
        embeddings = model.get_embeddings([content_for_embedding])
        
        if embeddings and len(embeddings) > 0:
            embedding_vector = embeddings[0].values
            print(f"   âœ… Embedding generado: {len(embedding_vector)} dimensiones")
            
            # Insertar en colecciÃ³n RAG con embedding
            rag_ref = db.collection('RAG').document()
            
            rag_document = {
                'type': 'event',
                'title': test_event['title'],
                'content': content_for_embedding,
                'description': test_event['description'],
                'citySlug': 'valencia',
                'cityName': 'Valencia',
                'adminIds': ['superadmin'],
                'metadata': {
                    'date': test_event['date'],
                    'time': test_event['time'],
                    'location': test_event['location'],
                    'category': test_event['category'],
                    'tags': test_event['tags'],
                    'sourceUrl': test_event['source'],
                    'confidence': test_event['confidence'],
                    'language': 'es'
                },
                'embedding': embedding_vector,
                'embeddingDimensions': len(embedding_vector),
                'searchKeywords': ['jazz', 'experimental', 'concierto', 'valencia'],
                'isActive': True,
                'hasEmbedding': True,
                'scrapedAt': firestore.SERVER_TIMESTAMP,
                'insertedByAgent': True,
                'agentTimestamp': firestore.SERVER_TIMESTAMP,
                'lastUpdated': firestore.SERVER_TIMESTAMP
            }
            
            rag_ref.set(rag_document)
            print("   âœ… Evento con embedding insertado en colecciÃ³n RAG")
            
            return True
        else:
            print("   âŒ No se pudo generar embedding")
            return False
            
    except Exception as e:
        print(f"âŒ Error probando RAG con embeddings: {e}")
        return False

def test_conceptual_search():
    """Probar bÃºsqueda conceptual con embeddings"""
    print("\nğŸ” Probando bÃºsqueda conceptual...")
    
    try:
        # Inicializar Firebase Admin
        if not firebase_admin._apps:
            firebase_admin.initialize_app()
        
        db = firestore.client()
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Consultas conceptuales de prueba
        conceptual_queries = [
            "mÃºsica en vivo y entretenimiento",
            "actividades culturales nocturnas",
            "eventos artÃ­sticos y creativos"
        ]
        
        for query in conceptual_queries:
            print(f"\n   ğŸ” BÃºsqueda conceptual: '{query}'")
            
            # Generar embedding de la consulta
            query_embeddings = model.get_embeddings([query])
            
            if not query_embeddings:
                print("   âŒ No se pudo generar embedding para la consulta")
                continue
            
            query_vector = query_embeddings[0].values
            
            # Obtener documentos con embeddings
            rag_docs = list(db.collection('RAG')
                           .where('hasEmbedding', '==', True)
                           .where('isActive', '==', True)
                           .stream())
            
            print(f"   ğŸ“Š Documentos con embeddings: {len(rag_docs)}")
            
            if len(rag_docs) == 0:
                print("   âš ï¸ No hay documentos con embeddings para comparar")
                continue
            
            # Calcular similitudes
            import numpy as np
            
            def cosine_similarity(vec1, vec2):
                vec1 = np.array(vec1)
                vec2 = np.array(vec2)
                norm1 = np.linalg.norm(vec1)
                norm2 = np.linalg.norm(vec2)
                if norm1 == 0 or norm2 == 0:
                    return 0
                return np.dot(vec1, vec2) / (norm1 * norm2)
            
            results = []
            for doc in rag_docs:
                doc_data = doc.to_dict()
                doc_embedding = doc_data.get('embedding', [])
                
                if doc_embedding:
                    similarity = cosine_similarity(query_vector, doc_embedding)
                    
                    if similarity > 0.1:
                        results.append({
                            'title': doc_data.get('title'),
                            'city': doc_data.get('citySlug'),
                            'similarity': similarity,
                            'type': doc_data.get('type')
                        })
            
            # Ordenar por similitud
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            # Mostrar resultados
            if results:
                print(f"   âœ… {len(results)} resultados encontrados:")
                for result in results[:3]:  # Top 3
                    print(f"      ğŸ¯ {result['similarity']:.3f} - {result['title']} ({result['city']})")
            else:
                print("   âš ï¸ No se encontraron resultados similares")
        
        return len(results) > 0
        
    except Exception as e:
        print(f"âŒ Error en bÃºsqueda conceptual: {e}")
        return False

def main():
    """Ejecutar todas las pruebas de embeddings"""
    print("ğŸš€ PRUEBAS DE EMBEDDINGS VECTORIALES")
    print("ğŸ§  BÃºsqueda Conceptual + ColecciÃ³n RAG Centralizada")
    print("=" * 70)
    
    tests = [
        ("GeneraciÃ³n de Embeddings", test_embedding_generation),
        ("Similitud Vectorial", test_vector_similarity),
        ("RAG con Embeddings", test_rag_with_embeddings),
        ("BÃºsqueda Conceptual", test_conceptual_search)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª {test_name}")
        print("-" * 50)
        
        try:
            if test_name == "GeneraciÃ³n de Embeddings":
                embedding_results = test_func()
                success = len(embedding_results) > 0 and any(r['success'] for r in embedding_results)
            else:
                success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"âŒ Error en {test_name}: {e}")
            results.append((test_name, False))
    
    # Resumen final
    print("\n" + "=" * 70)
    print("ğŸ“Š RESUMEN - EMBEDDINGS VECTORIALES")
    print("=" * 70)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nğŸ¯ Resultado: {passed}/{total} pruebas exitosas")
    
    if passed == total:
        print("ğŸŠ Â¡EMBEDDINGS VECTORIALES COMPLETAMENTE OPERATIVOS!")
        print("ğŸ§  BÃºsqueda conceptual implementada")
        print("ğŸ—‚ï¸ ColecciÃ³n RAG con vectores funcional")
        print("ğŸ” Similitud semÃ¡ntica funcionando")
    else:
        print("âš ï¸ Algunos componentes necesitan atenciÃ³n")
    
    print(f"\nğŸ§  CAPACIDADES IMPLEMENTADAS:")
    print(f"   â€¢ âœ… GeneraciÃ³n de embeddings con text-embedding-005")
    print(f"   â€¢ âœ… CÃ¡lculo de similitud coseno")
    print(f"   â€¢ âœ… BÃºsqueda vectorial conceptual")
    print(f"   â€¢ âœ… Almacenamiento de vectores en Firestore")
    print(f"   â€¢ âœ… ColecciÃ³n RAG centralizada con embeddings")

if __name__ == "__main__":
    main()
