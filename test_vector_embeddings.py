#!/usr/bin/env python3
"""
Probar generaci√≥n de embeddings y b√∫squeda vectorial
"""

import sys
import json

# Agregar el path del agente
sys.path.insert(0, '/Users/tonillorens/Desktop/wearecity_app/.venv/lib/python3.12/site-packages')

try:
    import firebase_admin
    from firebase_admin import credentials, firestore
    import vertexai
    from vertexai.language_models import TextEmbeddingModel
    
    print("‚úÖ Dependencias importadas correctamente")
except ImportError as e:
    print(f"‚ùå Error importando dependencias: {e}")
    sys.exit(1)

def test_embedding_generation():
    """Probar generaci√≥n de embeddings"""
    print("üß† Probando generaci√≥n de embeddings...")
    
    try:
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        
        # Usar el modelo de embeddings
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Textos de prueba
        test_texts = [
            "Festival de m√∫sica en Valencia con conciertos gratuitos",
            "Tr√°mites de empadronamiento en el ayuntamiento",
            "Fiestas tradicionales de Moros y Cristianos",
            "Informaci√≥n tur√≠stica sobre playas y museos"
        ]
        
        embeddings_results = []
        
        for text in test_texts:
            print(f"   üîç Generando embedding para: {text[:50]}...")
            
            try:
                embeddings = model.get_embeddings([text])
                
                if embeddings and len(embeddings) > 0:
                    vector = embeddings[0].values
                    embeddings_results.append({
                        "text": text,
                        "embedding": vector,
                        "dimensions": len(vector),
                        "success": True
                    })
                    print(f"   ‚úÖ Embedding generado: {len(vector)} dimensiones")
                else:
                    print(f"   ‚ùå No se pudo generar embedding")
                    embeddings_results.append({
                        "text": text,
                        "embedding": [],
                        "dimensions": 0,
                        "success": False
                    })
                    
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
                embeddings_results.append({
                    "text": text,
                    "embedding": [],
                    "dimensions": 0,
                    "success": False,
                    "error": str(e)
                })
        
        # Resumen
        successful = sum(1 for r in embeddings_results if r['success'])
        print(f"\nüìä Resumen embeddings:")
        print(f"   ‚úÖ Exitosos: {successful}/{len(test_texts)}")
        
        if successful > 0:
            avg_dimensions = sum(r['dimensions'] for r in embeddings_results if r['success']) / successful
            print(f"   üìè Dimensiones promedio: {avg_dimensions:.0f}")
        
        return embeddings_results
        
    except Exception as e:
        print(f"‚ùå Error en generaci√≥n de embeddings: {e}")
        return []

def test_vector_similarity():
    """Probar c√°lculo de similitud vectorial"""
    print("\nüî¢ Probando c√°lculo de similitud vectorial...")
    
    try:
        import numpy as np
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Textos relacionados para probar similitud
        queries = [
            "festivales de m√∫sica",
            "conciertos y eventos culturales",
            "tr√°mites municipales",
            "empadronamiento y documentaci√≥n"
        ]
        
        documents = [
            "Festival de m√∫sica en Valencia con conciertos gratuitos",
            "Concierto de jazz en el teatro municipal",
            "Tr√°mites de empadronamiento en el ayuntamiento",
            "Documentos necesarios para registrarse como residente"
        ]
        
        print("   üîç Generando embeddings para consultas y documentos...")
        
        # Generar embeddings
        query_embeddings = model.get_embeddings(queries)
        doc_embeddings = model.get_embeddings(documents)
        
        def cosine_similarity(vec1, vec2):
            """Calcular similitud coseno"""
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0
            
            return np.dot(vec1, vec2) / (norm1 * norm2)
        
        print("\n   üìä Matriz de similitudes:")
        print("   " + "-" * 60)
        
        # Calcular similitudes
        for i, query in enumerate(queries):
            print(f"   üîç '{query[:30]}...'")
            
            similarities = []
            for j, doc in enumerate(documents):
                similarity = cosine_similarity(
                    query_embeddings[i].values,
                    doc_embeddings[j].values
                )
                similarities.append((doc[:40], similarity))
            
            # Ordenar por similitud
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # Mostrar los m√°s similares
            for doc_text, sim_score in similarities[:2]:
                print(f"      ‚úÖ {sim_score:.3f} - {doc_text}...")
        
        print("   ‚úÖ Similitud vectorial funcionando correctamente")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en similitud vectorial: {e}")
        return False

def test_rag_with_embeddings():
    """Probar inserci√≥n y b√∫squeda con embeddings"""
    print("\nüóÇÔ∏è Probando RAG con embeddings...")
    
    try:
        # Inicializar Firebase Admin
        if not firebase_admin._apps:
            firebase_admin.initialize_app()
        
        db = firestore.client()
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Datos de prueba con embeddings
        test_event = {
            "title": "Concierto de Jazz Vectorial",
            "description": "Concierto de jazz experimental con artistas locales en el auditorio municipal",
            "date": "2025-09-30",
            "time": "21:00",
            "location": "Auditorio Municipal, Valencia",
            "category": "musica",
            "tags": ["jazz", "experimental", "local", "auditorio"],
            "source": "test_vector_embeddings",
            "confidence": 0.95
        }
        
        # Generar embedding para el evento
        content_for_embedding = f"""
        T√≠tulo: {test_event['title']}
        Descripci√≥n: {test_event['description']}
        Ubicaci√≥n: {test_event['location']}
        Categor√≠a: {test_event['category']}
        Etiquetas: {', '.join(test_event['tags'])}
        Ciudad: Valencia
        """.strip()
        
        print("   üß† Generando embedding para evento de prueba...")
        embeddings = model.get_embeddings([content_for_embedding])
        
        if embeddings and len(embeddings) > 0:
            embedding_vector = embeddings[0].values
            print(f"   ‚úÖ Embedding generado: {len(embedding_vector)} dimensiones")
            
            # Insertar en colecci√≥n RAG con embedding
            rag_ref = db.collection('RAG').document()
            
            rag_document = {
                'type': 'event',
                'title': test_event['title'],
                'content': content_for_embedding,
                'description': test_event['description'],
                'citySlug': 'valencia',
                'cityName': 'Valencia',
                'adminIds': ['superadmin'],
                'metadata': {
                    'date': test_event['date'],
                    'time': test_event['time'],
                    'location': test_event['location'],
                    'category': test_event['category'],
                    'tags': test_event['tags'],
                    'sourceUrl': test_event['source'],
                    'confidence': test_event['confidence'],
                    'language': 'es'
                },
                'embedding': embedding_vector,
                'embeddingDimensions': len(embedding_vector),
                'searchKeywords': ['jazz', 'experimental', 'concierto', 'valencia'],
                'isActive': True,
                'hasEmbedding': True,
                'scrapedAt': firestore.SERVER_TIMESTAMP,
                'insertedByAgent': True,
                'agentTimestamp': firestore.SERVER_TIMESTAMP,
                'lastUpdated': firestore.SERVER_TIMESTAMP
            }
            
            rag_ref.set(rag_document)
            print("   ‚úÖ Evento con embedding insertado en colecci√≥n RAG")
            
            return True
        else:
            print("   ‚ùå No se pudo generar embedding")
            return False
            
    except Exception as e:
        print(f"‚ùå Error probando RAG con embeddings: {e}")
        return False

def test_conceptual_search():
    """Probar b√∫squeda conceptual con embeddings"""
    print("\nüîç Probando b√∫squeda conceptual...")
    
    try:
        # Inicializar Firebase Admin
        if not firebase_admin._apps:
            firebase_admin.initialize_app()
        
        db = firestore.client()
        
        # Inicializar Vertex AI
        vertexai.init(project="wearecity-2ab89", location="us-central1")
        model = TextEmbeddingModel.from_pretrained("text-embedding-005")
        
        # Consultas conceptuales de prueba
        conceptual_queries = [
            "m√∫sica en vivo y entretenimiento",
            "actividades culturales nocturnas",
            "eventos art√≠sticos y creativos"
        ]
        
        for query in conceptual_queries:
            print(f"\n   üîç B√∫squeda conceptual: '{query}'")
            
            # Generar embedding de la consulta
            query_embeddings = model.get_embeddings([query])
            
            if not query_embeddings:
                print("   ‚ùå No se pudo generar embedding para la consulta")
                continue
            
            query_vector = query_embeddings[0].values
            
            # Obtener documentos con embeddings
            rag_docs = list(db.collection('RAG')
                           .where('hasEmbedding', '==', True)
                           .where('isActive', '==', True)
                           .stream())
            
            print(f"   üìä Documentos con embeddings: {len(rag_docs)}")
            
            if len(rag_docs) == 0:
                print("   ‚ö†Ô∏è No hay documentos con embeddings para comparar")
                continue
            
            # Calcular similitudes
            import numpy as np
            
            def cosine_similarity(vec1, vec2):
                vec1 = np.array(vec1)
                vec2 = np.array(vec2)
                norm1 = np.linalg.norm(vec1)
                norm2 = np.linalg.norm(vec2)
                if norm1 == 0 or norm2 == 0:
                    return 0
                return np.dot(vec1, vec2) / (norm1 * norm2)
            
            results = []
            for doc in rag_docs:
                doc_data = doc.to_dict()
                doc_embedding = doc_data.get('embedding', [])
                
                if doc_embedding:
                    similarity = cosine_similarity(query_vector, doc_embedding)
                    
                    if similarity > 0.1:
                        results.append({
                            'title': doc_data.get('title'),
                            'city': doc_data.get('citySlug'),
                            'similarity': similarity,
                            'type': doc_data.get('type')
                        })
            
            # Ordenar por similitud
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            # Mostrar resultados
            if results:
                print(f"   ‚úÖ {len(results)} resultados encontrados:")
                for result in results[:3]:  # Top 3
                    print(f"      üéØ {result['similarity']:.3f} - {result['title']} ({result['city']})")
            else:
                print("   ‚ö†Ô∏è No se encontraron resultados similares")
        
        return len(results) > 0
        
    except Exception as e:
        print(f"‚ùå Error en b√∫squeda conceptual: {e}")
        return False

def main():
    """Ejecutar todas las pruebas de embeddings"""
    print("üöÄ PRUEBAS DE EMBEDDINGS VECTORIALES")
    print("üß† B√∫squeda Conceptual + Colecci√≥n RAG Centralizada")
    print("=" * 70)
    
    tests = [
        ("Generaci√≥n de Embeddings", test_embedding_generation),
        ("Similitud Vectorial", test_vector_similarity),
        ("RAG con Embeddings", test_rag_with_embeddings),
        ("B√∫squeda Conceptual", test_conceptual_search)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nüß™ {test_name}")
        print("-" * 50)
        
        try:
            if test_name == "Generaci√≥n de Embeddings":
                embedding_results = test_func()
                success = len(embedding_results) > 0 and any(r['success'] for r in embedding_results)
            else:
                success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"‚ùå Error en {test_name}: {e}")
            results.append((test_name, False))
    
    # Resumen final
    print("\n" + "=" * 70)
    print("üìä RESUMEN - EMBEDDINGS VECTORIALES")
    print("=" * 70)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nüéØ Resultado: {passed}/{total} pruebas exitosas")
    
    if passed == total:
        print("üéä ¬°EMBEDDINGS VECTORIALES COMPLETAMENTE OPERATIVOS!")
        print("üß† B√∫squeda conceptual implementada")
        print("üóÇÔ∏è Colecci√≥n RAG con vectores funcional")
        print("üîç Similitud sem√°ntica funcionando")
    else:
        print("‚ö†Ô∏è Algunos componentes necesitan atenci√≥n")
    
    print(f"\nüß† CAPACIDADES IMPLEMENTADAS:")
    print(f"   ‚Ä¢ ‚úÖ Generaci√≥n de embeddings con text-embedding-005")
    print(f"   ‚Ä¢ ‚úÖ C√°lculo de similitud coseno")
    print(f"   ‚Ä¢ ‚úÖ B√∫squeda vectorial conceptual")
    print(f"   ‚Ä¢ ‚úÖ Almacenamiento de vectores en Firestore")
    print(f"   ‚Ä¢ ‚úÖ Colecci√≥n RAG centralizada con embeddings")

if __name__ == "__main__":
    main()
